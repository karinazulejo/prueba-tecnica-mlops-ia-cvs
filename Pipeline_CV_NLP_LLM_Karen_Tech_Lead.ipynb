{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc6311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencias principales\n",
    "!pip install -q pdfplumber groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92cea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from pathlib import Path\n",
    "\n",
    "uploaded = files.upload()\n",
    "ZIP_NAME = next(iter(uploaded.keys()))\n",
    "DATA_ROOT = Path(\"data_cvs\")\n",
    "DATA_ROOT.mkdir(exist_ok=True)\n",
    "ZIP_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e32ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile(ZIP_NAME) as zf:\n",
    "    zf.extractall(DATA_ROOT)\n",
    "\n",
    "pdf_files = sorted(DATA_ROOT.rglob(\"*.pdf\"))\n",
    "print(f\"Se encontraron {len(pdf_files)} PDFs:\")\n",
    "for p in pdf_files:\n",
    "    print(\" -\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81bc9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "from pathlib import Path\n",
    "\n",
    "TXT_ROOT = Path(\"cvs_txt\")\n",
    "TXT_ROOT.mkdir(exist_ok=True)\n",
    "\n",
    "def pdf_to_text(pdf_path: Path, txt_path: Path) -> None:\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        pages_text = [page.extract_text() or \"\" for page in pdf.pages]\n",
    "    text = \"\\n\".join(pages_text)\n",
    "    with txt_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "for pdf_path in pdf_files:\n",
    "    txt_path = TXT_ROOT / (pdf_path.stem + \".txt\")\n",
    "    pdf_to_text(pdf_path, txt_path)\n",
    "\n",
    "print(\"Conversión completada. Archivos TXT generados en:\", TXT_ROOT)\n",
    "for p in sorted(TXT_ROOT.glob(\"*.txt\")):\n",
    "    print(\" -\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef49924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "import os, json, re, logging\n",
    "from datetime import datetime\n",
    "\n",
    "# En Colab puedes definir aquí tu API key (no subirla a GitHub):\n",
    "# os.environ[\"GROQ_API_KEY\"] = \"gsk_...\"\n",
    "\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    raise RuntimeError(\"Defina la variable de entorno GROQ_API_KEY antes de continuar.\")\n",
    "\n",
    "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "def extract_email(text: str):\n",
    "    m = re.search(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\", text)\n",
    "    return m.group(0) if m else None\n",
    "\n",
    "def extract_phone(text: str):\n",
    "    m = re.search(r\"(\\+?\\d{1,3})?[-.\\s]?\\(?\\d{2,3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\", text)\n",
    "    return m.group(0) if m else None\n",
    "\n",
    "def extract_years_experience(text: str):\n",
    "    m = re.search(r\"(\\d+)\\s+(años|years|años de experiencia)\", text, re.IGNORECASE)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def extract_llm_data(text: str) -> dict:\n",
    "    system_prompt = (\n",
    "        \"Eres un modelo experto en análisis de hojas de vida. \"\n",
    "        \"Extrae solo datos respaldados por el texto. \"\n",
    "        \"Si un dato no está claro, devuelve null. \"\n",
    "        \"Responde siempre en JSON válido, sin comentarios adicionales.\"\n",
    "    )\n",
    "\n",
    "    user_prompt = f\"\"\"Analiza el siguiente CV y devuelve un JSON con esta estructura EXACTA:\n",
    "\n",
    "{{\n",
    "  \"nombre\": string | null,\n",
    "  \"formacion_ia\": \"Sí\" | \"No\" | null,\n",
    "  \"score_cv\": number,\n",
    "  \"confianza\": number\n",
    "}}\n",
    "\n",
    "CV:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"llama-3.1-8b-instant\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "        )\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        try:\n",
    "            data = json.loads(content)\n",
    "        except Exception:\n",
    "            logging.warning(\"Respuesta no era JSON perfecto. Se aplica fallback neutro.\")\n",
    "            data = {\"nombre\": None, \"formacion_ia\": None, \"score_cv\": 0.0, \"confianza\": 0.0}\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Fallo en llamada al LLM: {e}\")\n",
    "        data = {\"nombre\": None, \"formacion_ia\": None, \"score_cv\": 0.0, \"confianza\": 0.0}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de8728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cv(text: str, filename: str) -> dict:\n",
    "    email = extract_email(text)\n",
    "    phone = extract_phone(text)\n",
    "    years = extract_years_experience(text)\n",
    "    llm_data = extract_llm_data(text)\n",
    "\n",
    "    metricas = {\n",
    "        \"email_detectado\": 1 if email else 0,\n",
    "        \"telefono_detectado\": 1 if phone else 0,\n",
    "        \"experiencia_detectada\": 1 if years else 0,\n",
    "    }\n",
    "\n",
    "    result = {\n",
    "        \"nombre\": llm_data.get(\"nombre\"),\n",
    "        \"email\": email,\n",
    "        \"telefono\": phone,\n",
    "        \"anios_experiencia\": years,\n",
    "        \"formacion_ia\": llm_data.get(\"formacion_ia\"),\n",
    "        \"score_cv\": llm_data.get(\"score_cv\"),\n",
    "        \"confianza\": llm_data.get(\"confianza\"),\n",
    "        \"metricas\": metricas,\n",
    "        \"metadata\": {\n",
    "            \"modelo_llm\": \"llama-3.1-8b-instant\",\n",
    "            \"version_pipeline\": \"1.1\",\n",
    "            \"fecha_ejecucion\": datetime.utcnow().isoformat(),\n",
    "            \"archivo_origen\": filename,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    if result[\"email\"] is None or result[\"nombre\"] is None:\n",
    "        result[\"score_cv\"] = 0.0\n",
    "        result[\"confianza\"] = min(result.get(\"confianza\") or 0.0, 0.3)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf091ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "INPUT_DIR = TXT_ROOT\n",
    "OUTPUT_JSON = Path(\"resultados_cvs.json\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for txt_path in sorted(INPUT_DIR.glob(\"*.txt\")):\n",
    "    logging.info(f\"Procesando archivo: {txt_path.name}\")\n",
    "    with txt_path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        text = f.read()\n",
    "    cv_result = process_cv(text, txt_path.name)\n",
    "    results.append(cv_result)\n",
    "\n",
    "with OUTPUT_JSON.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Se procesaron {len(results)} CVs\")\n",
    "print(f\"Archivo JSON generado en: {OUTPUT_JSON.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eceb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"resultados_cvs.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Registros en resultados_cvs.json: {len(data)}\")\n",
    "data[:2]"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
